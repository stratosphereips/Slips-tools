---
title: "R Notebook"
output: html_notebook
---
```{r}
library(tidyverse)
library(jsonlite)
```
```{r}
evals_file<-"/home/harpo/Dropbox/ongoing-work/git-repos/slips-tools/llm-unittest/results/evals_openai_8b.csv"
cols_file<-"/home/harpo/Dropbox/ongoing-work/git-repos/slips-tools/llm-unittest/results/cols_export_openai_8b.json"
```


```{r}
bitnet_evals_file<-"/home/harpo/Dropbox/ongoing-work/git-repos/slips-tools/llm-unittest/results/evals_bitnet.csv"
bitnet_cols_file<-"/home/harpo/Dropbox/ongoing-work/git-repos/slips-tools/llm-unittest/results/cols_export_bitnet.json"

```

```{r}


```


Here we have the information about the description of the test
```{r}
promptfoo_data_test<-read_csv(evals_file)
```
```{r}
promptfoo_data_test_bitnet<-read_csv(bitnet_evals_file)
promptfoo_data_test<- rbind(promptfoo_data_test,promptfoo_data_test_bitnet)
```


```{r}
promptfoo_data_test <- promptfoo_data_test %>% rename(evalId="ID")
```
Here we have the actual tests
```{r}
promptfoo_data<-fromJSON(cols_file,flatten = TRUE)
promptfoo_data_bitnet<-fromJSON(bitnet_cols_file,flatten = TRUE)
promptfoo_data <- rbind(promptfoo_data,promptfoo_data_bitnet)
#promptfoo_data %>% select(description) %>% unique()
```

```{r}
promptfoo_data<-left_join(promptfoo_data,promptfoo_data_test,by="evalId")
promptfoo_data
```

```{r}
library(dplyr)
library(tidyr)

pivot_scores <- promptfoo_data %>%
  group_by(provider, Description) %>%
  summarize(
    total_pass = sum(metrics.testPassCount),
    total_fail = sum(metrics.testFailCount),
    .groups = "drop"
  ) %>%
  mutate(pass_rate = round(100 * total_pass / (total_pass + total_fail), 2)) %>%
  select(provider, Description, pass_rate) %>%
  pivot_wider(
    names_from = Description,
    values_from = pass_rate
  )

pivot_scores<-pivot_scores %>% filter(! provider %in% c("openai:chat:qwen2.5:3b-instruct-q8_0",
                                         "openai:chat:smollm:1.7b-instruct-v0.2-q5_K_M",
                                         "openai:chat:smollm:1.7b-instruct-v0.2-q8_0"))
```
```{r fig.height=8, fig.width=8}
library(ggplot2)
library(tidyr)

# Assuming `pivot_scores` from previous step is already created
long_data <- pivot_scores %>%
  pivot_longer(-provider, names_to = "Description", values_to = "pass_rate")

long_data$provider <- gsub("openai:chat:", "", long_data$provider)


ggplot(long_data, aes(x = Description, y = provider, fill = pass_rate)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "red", mid = "yellow", high = "darkgreen", midpoint = 50, na.value = "grey90") +
  #scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 50, na.value = "grey90") +
  #scale_fill_viridis_c(option = "C", na.value = "grey90")+
  labs(title = "Model Performance on promptfoo tests", x = "Test Description", y = "Model", fill = "Pass Rate (%)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

ggsave(filename = "/home/harpo/Dropbox/ongoing-work/git-repos/slips-tools/llm-unittest/results/models_heatmap.png",width = 8, height = 6, units = "in")
```

